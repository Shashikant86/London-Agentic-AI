# DSPy GEPA Performance Summary

Quick reference for DSPy GEPA optimization results with local Ollama models.

## üöÄ **Full Configuration Comparison**

### Lightweight Models (llama3.2:1b + llama3.1:8b) ‚≠ê Best for Learning
| Component | Before GEPA | After GEPA | Improvement |
|-----------|-------------|------------|-------------|
| **Audience Judge** | 27.78% | **55.56%** | **+100%** |
| **Comedian** | 100.0% | **100.0%** | Stable |
| **Runtime** | - | **6.5 min** | Fast |

### Medium Models (llama3.1:8b + qwen3:8b) 
| Component | Before GEPA | After GEPA | Improvement |
|-----------|-------------|------------|-------------|
| **Audience Judge** | 44.44% | **44.44%** | **No change** |
| **Comedian** | 100.0% | **87.5%** | Slight drop |
| **Runtime** | - | **~10+ min** | Slower |

### High-Performance Models (gpt-oss:20b + gpt-oss:120b) ‚≠ê Best Results
| Component | Before GEPA | After GEPA | Improvement |
|-----------|-------------|------------|-------------|
| **Audience Judge** | 27.78% | **72.22%** | **+160%** |
| **Comedian** | 62.5% | **100.0%** | **+60%** |
| **Runtime** | - | **15-20 min** | Premium |

## ‚è±Ô∏è **Runtime Performance**

| Phase | Duration |
|-------|----------|
| **Total Runtime** | **6.5 minutes** |
| Environment Setup | 5 seconds |
| Dataset Creation | 15 seconds |
| Basic Evaluations | 30 seconds |
| GEPA Optimization | 4 minutes |
| Final Testing | 15 seconds |

## üí° **Model Configuration**

```bash
# Default models (tested)
python evaluator_optimizer_dspy.py
# Student: llama3.2:1b (1.3B parameters)
# Teacher: llama3.1:8b (8B parameters)
```

## üìä **Local Ollama Results Summary**

| Configuration | Runtime | Audience Judge Accuracy | Best Use Case |
|---------------|---------|------------------------|---------------|
| **Lightweight** (llama3.2:1b + llama3.1:8b) | 6.5 min | 55.56% | Learning GEPA concepts |
| **Medium** (llama3.1:8b + qwen3:8b) | ~10+ min | 44.44% | Baseline comparison |
| **High-Performance** (gpt-oss:20b + gpt-oss:120b) | 15-20 min | 72.22% | Best quality results |

## üîç **Key Insights Across All Configurations**

### Why Lightweight Models Excel for Learning
- **Dramatic Visible Gains**: +100% improvement shows GEPA working clearly
- **Fast Iteration**: 6.5 minutes allows rapid experimentation
- **Resource Efficiency**: Accessible to most systems (16GB+ RAM)

### Why Medium Models Plateau
- **Optimization Ceiling**: Already near their 8B parameter limits  
- **No Improvement**: GEPA can't enhance already-capable baselines
- **Diminishing Returns**: Better starting point but nowhere to go

### Why High-Performance Models Dominate
- **Exceptional Gains**: +160% audience judge improvement (best of all configs)
- **Perfect Results**: 100% comedian accuracy after optimization
- **Professional Quality**: Both components reach near-optimal performance
- **Worth the Wait**: 15-20 minutes for dramatically superior results

## üéØ **Bottom Line & Recommendations**

### For Learning DSPy/GEPA Concepts
‚úÖ **Use lightweight models**: llama3.2:1b + llama3.1:8b  
‚úÖ **Dramatic +100% gains show optimization clearly**  
‚úÖ **Fast 6.5-minute runtime for rapid iteration**  

### For Best Performance Results  
‚úÖ **Use high-performance models**: gpt-oss:20b + gpt-oss:120b  
‚úÖ **Exceptional +160% audience judge improvement**  
‚úÖ **Perfect 100% comedian accuracy after optimization**  
‚úÖ **Professional-grade results worth the 15-20 minute runtime**  

### Avoid for Optimization Learning
‚ùå **Medium models show no improvement** - not educational for GEPA learning

See `BENCHMARKS.md` for detailed technical analysis.